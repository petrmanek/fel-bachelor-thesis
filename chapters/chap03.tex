\chapter{Communication Protocol}
\label{protocol:introduction}

In this chapter, we move our focus from the data itself to the JSON Timepix Protocol, a communication protocol we use to transmit Timepix footage for the purposes of visualization. We describe overall scheme of communication and define JSTP in a formal way.

\section{Remote Access}
In the previous chapter, we have defined a database capable of storing footage captured by the ATLAS-TPX network at CERN. Since this database is based on a UNIX file system, multiple users can access it simultaneously by either directly interacting with the computer responsible for its operation, or by using some of the supported\footnote{Recall that in section \ref{db:supported-protocols} we define that our database supports FTP, SMB, SSH, AFP and HTTP access.} network protocols to interact with it remotely.

Since our database already supports concurrent network access for multiple users, defining another dedicated communication protocol such as JSTP seems rather redundant. So, what advantages does this approach offer? The primary motivation for the existence of JSTP is the web visualization UI, which is the subject of Chapter \ref{chapter:web-visualization}. In this application, our users want to observe recorded footage frame by frame. If we do not define our own protocol to facilitate transmissions of individual frames, we are bound to use one of storage formats listed in section \ref{db:storage-formats}, none of which is particularly suitable for this task. For instance, the Multi-Frame format stores data in multiple files, implying that several parallel downloads would be required just to display even a single frame, possibly putting a strain on user's network connection in the process. The ROOT format uses its own compression algorithms, making it non-trivial to deflate in a website context. Lastly, since both ROOT and Multi-Frame store data in bulks, the information overhead to transmit a single frame would be unbearable, especially considering that files in question may be several gigabytes in size.

With this motivation in mind, let us now state several assumptions about our web visualization, and by extension JSTP. We expect to have multiple users connecting to our server over a local area network or through the Internet. We assume that our users want to see and possibly further inspect some of the frames captured by the ATLAS-TPX network, transmitted in units at a time. We do not wish to transmit all information from our data files, nor do we want to send continuous footage at streaming speeds. Instead, we define JSTP to enable simple access to the most important detector data, and to provide a brief overview of recent detector operation with emphasis on any irregular or pattern-defying events.

\subsection{Considerations}
Note that in designing our system, we would like to uphold a multi-layered architecture. This way, we maintain strict distinctions between individual components of the system (and the tasks they perform), making them in effect easily extensible, substitutable and perhaps even portable to other applications. Other benefit of this approach is that users of our system will always have freedom to choose a component, with which they wish to interact, in turn choosing the level of offered services, processing speed and algorithmic complexity.

\begin{figure}[t]
\begin{center}
	\begin{tikzpicture}[node distance=3pt,
	blueb/.style={
	  draw=black,
	  rounded corners,
	  text width=2.5cm,
	  font=\scriptsize,
	  align=center,
	  text height=12pt,
	  text depth=9pt
	},
	layerb/.style={
	  blueb,
	  draw=none
	},
	proprietaryb/.style={
	  blueb,
	  fill=gray!30
	}]

	\node[layerb] (Clients) {\textbf{Applications}};
	\node[proprietaryb,right=of Clients,text width=5cm+10pt] (VizUI) {Web visualization UI};
	\node[blueb,right=of VizUI,text width=5cm+10pt] (Apps) {Others \dots};

	\node[layerb,below=of Clients] (Protocols) {\textbf{Protocols}};
	\node[proprietaryb,right=of Protocols] (JSTP) {JSTP};
	\node[blueb,right=of JSTP] (HTTP) {HTTP};
	\node[blueb,right=of HTTP] (FileP) {FTP, SMB};
	\node[blueb,right=of FileP] (SQLP) {SQL queries};

	\node[layerb,below=of Protocols] (Servers) {\textbf{Servers}};
	\node[proprietaryb,right=of Servers] (DataS) {Data RPC};
	\node[blueb,right=of DataS] (WebS) {Static web};
	\node[blueb,right=of WebS] (FileS) {File servers};
	\node[blueb,right=of FileS] (SQLS) {PostgreSQL};

	\node[layerb,below=of Servers] (Data) {\textbf{Data Store}};
	\node[blueb,right=of Data] (ROOT) {ROOT};
	\node[blueb,right=of ROOT,text width=5cm+10pt] (MF) {Multi-frame \& single-frame};
	\node[proprietaryb,right=of MF] (SQLD) {Index DB};

	\node[blueb,below=2.4cm of HTTP,text width=13cm+26pt] (FileSystem) {UNIX-like file system (possibly EOS)};

	\begin{pgfonlayer}{background}
	\draw[blueb,draw=black] 
	  ([xshift=-8pt,yshift=8pt]current bounding box.north west) rectangle 
	  ([xshift=8pt,yshift=-8pt]current bounding box.south east);
	\end{pgfonlayer}
	\end{tikzpicture}

\caption{A multi-layered system. Proprietary components are emphasized by gray color.}
\label{fig:multilayered-diagram}
\end{center}
\end{figure}

We may imagine this as follows. Users who want a quick peek at the detector operation without any effort might decide to use the visualization UI in their web browser. The website is quite easy to use, does not require any particular skills to operate, and is capable of displaying frames captured by the detectors as well as overview of their operation. In contrast, users who want to retrieve data for experimentation or statistical aggregation might utilize SQL or JSTP as these two protocols are not designed to interact with humans, but with other applications, most notably utilizable in scripts designed for custom data processing. Lastly, users in need of information, which is not displayed by the visualization UI nor transmitted by any of the mentioned protocols, are welcome to connect to the database storage facility remotely and directly download data files by means of some of the supported network transfer protocols. This concept is illustrated in Figure \ref{fig:multilayered-diagram}.

% CITACE: konkurenční projekty
We should also consider extensibility of JSTP in the future. With multiple concurrent projects such as MoEDAL-TPX\footnote{Similarly to ATLAS-TPX, MoEDAL-TPX is a network of Timepix devices installed within the MoEDAL experiment at CERN.}, SATRAM\footnote{SATRAM is a technology demonstration device carrying Timepix position-sensitive semiconductor pixel detector on board ESA’s Proba V satellite. \url{http://satram.utef.cvut.cz/}} and RISESat\footnote{RISESat is a microsatellite mission carrying several scientific instruments including a Timepix detector.}, it is likely that JSTP will be used for compatibility reasons in other applications as well. It should therefore allow for limited variability, gracefully handling minor alterations in transmitted data structures.

\subsection{Requirements}
Let us now list all formal requirements on JSTP. The most basic one is that the protocol allows us to retrieve frames captured by the ATLAS-TPX network by their start time and device of origin. This might remind us of a similar requirement in the database definition (see section \ref{db:definition}), as it is the most likely user request. However unlike our database, JSTP must be able to transmit only those frames, which satisfy the user predicate, minimizing information overhead in the transmitted messages.

In the first version, we require JSTP only to transmit results of the cluster analysis, leaving door open for pixel matrix transmissions in the future. This indirectly implies that every message transmitted through JSTP containing a captured frame will have to consist of two parts: a header (containing detector configuration, position, orientation, etc.) and a body (containing a list of clusters, or possibly a pixel matrix).

To efficiently reference detectors in the ATLAS-TPX network, we require that JSTP provides an exhaustive list of network elements along with information about their availability in the system. This might seem a bit redundant at first, but consider that JSTP needs to be ready for situations when detectors malfunction, are replaced, or new detectors are installed in the network. These events might not be that uncommon, especially given the experimental nature of the project.

Lastly, in order to aid with navigation in large amounts of detector footage, we require JSTP to offer us a mechanism to generate statistics over larger periods of time. This information will help users find events of interest in overwhelming quantities of white noise, resembling the proverbial \textit{needle in a haystack}.

Apart from various file management network protocols we listed earlier, we do not place any data manipulation requirements on JSTP, implying that the protocol cannot be used for other than read-only access to detector footage.

\section{Underlying Standards}
JSTP is web protocol and as such, it utilizes HTTP as its underlying standard. This allows us to abstract ourselves from caveats of data transmission and compression, and to focus more on the transmitted data instead. By this declaration, we also indirectly  imply that JSTP is a request-response communication protocol between two types of agents: a server and a client. In its architecture, JSTP consists of two parts: a web service providing API for remote procedure calls (RPC) and a data format built atop of it to facilitate these calls. Since JSTP does not include any universal service description mechanism such as WSDL or WADL, all clients need to know its capabilities and calling conventions prior to initiating communication with the server. For data serialization, JSTP utilizes JavaScript Object Notation (JSON). This format has been selected for various reasons. It is simple to parse, offers an extensible tree structure and is very common among web services of this kind, as it is directly supported by the JavaScript client-side runtime used in the web visualization UI. Apart from JSON, JSTP does not offer nor accept communication in any other data formats.

Observant readers may ask whether JSTP web methods meet the standards of RESTful web services. While it is true that the protocol shows many traits often attributed to RESTful services (client-server model, stateless protocol, cacheability, layered system), it certainly does not satisfy all of them. For instance, JSTP does not uniquely identify resources by their URI because it does not offer any of the common CRUD operations. Moreover, in referencing entities, JSTP uses arbitrary identifiers (recall members \texttt{fid}, \texttt{frid} and \texttt{sid} of entities defined in section \ref{db:definition}), which are not passed in the URI but through an array in the request body. Moreover, JSTP does not offer a uniform interface, capable of negotiating data format according to client limitations. Instead, it forces clients to communicate strictly in JSON, adhering to its own data structures and calling conventions.

\section{Web Methods}
\label{jstp:web-methods}
The main component of JSTP is a web service, which can be described as a set of proprietary web methods. For the purpose of simplicity, in this section we provide only a semantical description of each method. Readers interested in full technical documentation of the methods are referred to Appendix \ref{apx:jstp-doc}.

\subsection{Detector List}
The first method is dedicated to providing an updated list of operational detectors in the ATLAS-TPX network.

As we mentioned earlier, we need to be ready for situations when the physical structure of the network changes due to malfunctions or upgrades. For these reasons, any client intending to retrieve frames from a specific detector must first consult the list provided by this method to verify, whether the device is still connected and operational. In addition, other clients unaware of the network's architecture may use this method to obtain an exhaustive listing of all currently available data sources.

Execution of this method requires no parameters. The server responds by transmitting a list of devices, from which data can be retrieved at the time of request. For detailed documentation of this method including examples of requests and responses, see section \ref{apx:jstp-sensors} of the Appendix.

\subsection{Overview of Acquisition}
To satisfy demands on navigation in voluminous amounts of data, we dedicate the second web method to providing an overview on detector acquisition. This is achieved by uniformly dividing a specific time period into finitely many time intervals, in which all relevant frames are gathered with respect to their start time (acquisition time is not considered). In every interval, frames are subsequently processed to produce aggregate statistics, which might indicate time points, where frames of interest are located. This approach is in its essence very similar to the binning procedure used when constructing histograms.

Clients calling this method are required to transmit five parameters in their request:

\begin{description}
	\item[Detector Predicate]
	A group of detector identifiers, restricting all processed frames by their device of origin.

	\item[Start Time, End Time]
	These parameters define the time period, in which we generate statistics. Obviously, the first parameter must be an earlier point of time than the latter.

	\item[Group Period]
	The duration of every interval in the partitioning of the time period. Should an imperfect partitioning occur, the number of intervals is always rounded up to the nearest integer, possibly exceeding the specified end time.

	Longer durations obviously result in a lower number of intervals, and in turn a lower number of returned data points. Shorter durations yield more data points, but may result in lengthy processing at server-side. For stability reasons, the server therefore requires that the duration of the group period results in at least 1 and at most 1024 intervals.

	\item[Normalized Mode]
	An option to compensate possible data distortions caused by variations in frame acquisition times. This setting is irrelevant in configurations, where users can be certain such variations do not occur.
\end{description}

If the server finds request parameters to be valid and succeeds in generating requested statistics, it responds by transmitting a list of data points, corresponding with intervals of the partitioning of the specified time period. Every data point includes three values:

\begin{description}
	\item[Cluster Counts]
	Sums of cluster counts from every frame in the interval, summed separately per every of the six cluster types (for type definitions, see section \ref{db:shape-classification}).

	\item[Frame Occupancy]
	Total number of non-zero pixels in all frames in the interval, indicating their levels of saturation.

	\item[Number of Frames]
	The count of frames aggregated in the interval.
\end{description}

For detailed documentation of this method including examples of requests and responses, see section \ref{apx:jstp-timeline} of the Appendix.

\subsection{Frame Search}
The third method serves to retrieve frames captured at any given point in time by a detector (or a group of detectors). As the method's name might suggest, time need not be exact, resulting in a search for the nearest frame operating on the scope of the index database. There are several search modes available, each offering a different strategy to find \textit{the master frame}. Once such frame is identified, its start time is then used to locate other frames from the remaining detectors, yielding at most one frame per every detector. In the first version of JSTP, we support two search modes:

\begin{description}
	\item[Sequential Forward Mode]
	The master frame is the frame with the start time nearest to, but greater or equal than the time parameter of the search.

	\item[Sequential Backward Mode]
	The master frame is the frame with the start time nearest to, but lower or equal than the time parameter of the search.

	%\item[Sequential Omnidirectional Mode]
	%\item[Exact Match Mode]
\end{description}

Let us demonstrate operation of these modes on a real world example. Suppose that we are interested in frames captured by two devices. Detector 1 captures frames every 0.25 seconds with acquisition time of 0.05 seconds, whereas detector 2 captures frames every 0.33 seconds with acquisition time of 0.27 seconds. If we set the search time to 0.4 seconds and search in the forward mode, the third frame captured by detector 1 will be designated as the master frame. Since the start time of this frame is 0.5 seconds, the second chosen frame will be the second frame captured by detector 2 as its start time is 0.33 seconds and its end time is 0.6 seconds. This scenario is depicted in Figure \ref{fig:frame-search-forward}. If we to use the backward mode instead, the second frame captured by detector 2 will be designated as the master frame. Since its start time is 0.33 seconds and there is a gap in detector 1 footage between 0.3 seconds (end time of the second frame) and 0.5 seconds (start time of the third frame), the algorithm will return no frame for the other detector. This is illustrated in Figure \ref{fig:frame-search-backward}.

% TODO: doplnit dva obrázky

\begin{figure}[t]
\begin{center}
	\begin{subfigure}[b]{0.4\textwidth}
	\Large
	\begin{tikztimingtable}
		\textnormal{D1}   & zz D{1}zzzz D{2}zzzz D{3}zzzz ;[fill=yellow!50]D{4};[fill=none] zzzz D{}         \\
		\textnormal{D2}   & zz 5D{1}z ;[fill=gray!30]5D{2};[fill=none]z 2D{}  \\
		\textnormal{D3}   & zz 2D{1}z   2D{2}z   2D{3}z   ;[fill=gray!30]2D{4};[fill=none] z    2D{5}z 0.5D{}   \\
		\extracode
	\begin{pgfonlayer}{background}
	\vertlines[help  lines]{1,9,10,13}
	\end{pgfonlayer}
	\end{tikztimingtable}
	\caption{Forward search.}
	\label{fig:frame-search-forward}
	\end{subfigure}
	~ %spacing
	\begin{subfigure}[b]{0.4\textwidth}\Large
	\begin{tikztimingtable}
		\textnormal{D1}   & zz D{1}zzzz D{2}zzzz D{3}zzzz D{4}zzzz D{}         \\
		\textnormal{D2}   & zz 5D{1}z ;[fill=gray!30]5D{2};[fill=none]z 2D{}  \\
		\textnormal{D3}   & zz 2D{1}z   2D{2}z   2D{3}z   ;[fill=yellow!50]2D{4};[fill=none] z    2D{5}z 0.5D{}   \\
		\extracode
	\begin{pgfonlayer}{background}
	\vertlines[help  lines]{1,8.5,9,13}
	\end{pgfonlayer}
	\end{tikztimingtable}
	\caption{Backward search.}
	\label{fig:frame-search-backward}
	\end{subfigure}

\caption{Time diagram of frame search illustrating behavioral differences between search modes. Individual blocks correspond with periods of detector acquisition. Emphasized blocks are returned as the search result (yellow marks the master frame).}
\label{fig:frame-search}
\end{center}
\end{figure}

To summarize, clients calling this method are required to specify four parameters:
\begin{description}
	\item[Time of Search]
	The point in time used as a starting point of the search.

	\item[Detector Predicate]
	A group of detector identifiers, restricting retrieved frames by their device of origin.

	\item[Search Mode]
	A strategy to select the master frame based on the time of search and available detector footage.

	\item[Integral Frames]
	Number of consecutive frames to be integrated for every device.
\end{description}

If the server finds request parameters to be valid and succeeds in locating at least one frame, it responds by transmitting the start time of the master frame, followed by headers and bodies of all found frames, corresponding with the order of identifiers in the detector predicate of the request. Frame bodies are transmitted in the form of cluster lists (for properties of clusters, see section \ref{db:cluster-properties}). Detailed documentation of this method, including examples of requests and responses, is available in section \ref{apx:jstp-frame} of the Appendix.

\section{Miscellaneous}
JSTP has been originally designed to serve solely as a data transmission component of the visualization UI. Over time, it has however grown to be a more complex protocol, with applications in other projects than ATLAS-TPX and outside the conventional task of data visualization. It is the intention of author to continue development of this protocol with further releases in the future, eventually decoupling it from the Timepix chip and abstracting it to the point where it could be utilized in combinations with different hardware.

Since the amount of data in our database is expected to become rather overwhelming, the protocol itself is structured and meant to be used in a top-down model (see Figure \ref{fig:jstp-uml}), allowing clients to gradually refine parameters of their requests and locate the information they seek, while avoiding transmission of data in overly granular bulks. In other cases, the protocol minimizes information overhead by requiring strong usage of predicates operating on the index database.

Note that in the protocol definition, we do not specify whether the results of individual web method calls are cacheable by clients. This is due to the diversified nature of its applications. Since HTTP already contains its own caching logic\footnote{Caching in HTTP is controlled by values of headers provided in every response message. Relevant header names are: \texttt{Cache-Control}, \texttt{Expires} and \texttt{Pragma}.}, we encourage all clients to comply with strategies described in \cite{HTTP1999}, section 13, as JSTP servers are permitted to use this mechanism to emply different caching policies for individual response messages. Analogous declaration is used for data compression (for HTTP specification, see section 3.5 of \cite{HTTP1999}).

\begin{figure}[t]
\begin{center}
	\begin{sequencediagram}
		\newthread{c}{:JstpClient}
		\newinst[2]{s}{:JstpServer}
		\newinst[1]{idb}{:IndexDatabase}
		\newinst{fdb}{:FileDatabase}

		\begin{call}{c}{detectorList()}{s}{device list}
			\begin{call}{s}{selectSensors()}{idb}{device list}
			\end{call}
		\end{call}
		
		\begin{sdblock}{Until significant data is found}{}
			\begin{call}{c}{acqOverview()}{s}{statistics}
				\begin{call}{s}{selectFiles()}{idb}{affected files}
				\end{call}
				\begin{call}{s}{selectFrames()}{idb}{statistics}
					\begin{callself}{idb}{\small aggregate()}{}
					\end{callself}
				\end{call}
			\end{call}
		\end{sdblock}
		
		\begin{call}{c}{frameSearch()}{s}{found frames}
			\begin{call}{s}{selectFrames()}{idb}{master frame}
			\end{call}
			\begin{sdblock}{For every device}{}
				\begin{call}{s}{selectFrames()}{idb}{entry indices}
				\end{call}
				\begin{call}{s}{readFile()}{fdb}{frame contents}
				\end{call}
			\end{sdblock}
		\end{call}
	\end{sequencediagram}

\caption{UML diagram depicting expected interactions between JSTP client and server, hinting levels of processing complexity at server-side.}
\label{fig:jstp-uml}
\end{center}
\end{figure}









