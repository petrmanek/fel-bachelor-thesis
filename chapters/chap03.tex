\chapter{Communication Protocol}
\label{protocol:introduction}
This chapter describes the JSON Timepix Protocol, a communication protocol used to transmit TPX footage for the purposes of visualization.

\section{Remote Access}
Since the database defined in the previous chapter is based on a UNIX file system, multiple users can access it simultaneously by either directly interacting with the computer responsible for its operation, or by using some of the supported protocols\footnote{Recall that the section \ref{db:supported-protocols} mentions access over FTP, SMB, SSH, AFP and HTTP.} to interact with it remotely over a network.

Due to this capability, one might argue that defining another dedicated communication protocol such as JSTP seems rather redundant. What advantages does this approach offer? The primary motivation for the existence of JSTP is the web visualization UI, which is described in the Chapter \ref{chapter:server}. It is expected that users of such application would want to observe recorded footage frame by frame. If no protocol is defined to facilitate transmissions of individual frames from the database to the visualization UI, data has to be transferred in one of the formats listed in section \ref{db:storage-formats}, none of which is particularly suitable for this task.

For instance, the plain text format stores data in multiple files implying that several parallel downloads would be required, possibly putting strain on user's network connection in the process. The ROOT format on the other hand uses its own compression algorithms, making it non-trivial to deflate in a website context. Lastly, since both ROOT and plain text formats store data in bulks, the information overhead to transmit units of frames would be nearly unbearable, especially considering that data files in question may be several gigabytes in size.

With this motivation in mind, JSTP is defined to effectively replace both formats in such situations. It is expected that multiple users would connect to a JSTP server over a local area network or through the Internet, possibly at the same time. Every user is assumed to have intentions to browse through or further inspect some of the frames captured by the ATLAS-TPX network, transmitted in units at a time. Note that JSTP is not designed to transmit all information from the data files, nor send continuous footage at streaming speeds. Instead, JSTP enables simple access to the most important detector data, and provides brief overview of recent detector operation with emphasis on any irregular or pattern-defying events.

\subsection{Considerations}
In definition, a multi-layered system architecture is upheld. This primarily serves to create strict distinctions between individual components of the system and the tasks they perform, making them in effect easily extensible, substitutable and perhaps even portable to other applications. Other benefit of this approach is that users always have freedom to choose a component, with which they wish to interact, in effect choosing the level of offered services, processing speeds and algorithmic complexity.

\begin{figure}[t]
\begin{center}
	\begin{tikzpicture}[node distance=3pt,
	blueb/.style={
	  draw=black,
	  rounded corners,
	  text width=2.5cm,
	  font=\scriptsize,
	  align=center,
	  text height=12pt,
	  text depth=9pt
	},
	layerb/.style={
	  blueb,
	  draw=none
	},
	proprietaryb/.style={
	  blueb,
	  fill=gray!30
	}]

	\node[layerb] (Clients) {\textbf{Applications}};
	\node[proprietaryb,right=of Clients,text width=5cm+10pt] (VizUI) {Web visualization UI};
	\node[blueb,right=of VizUI,text width=5cm+10pt] (Apps) {Others \dots};

	\node[layerb,below=of Clients] (Protocols) {\textbf{Protocols}};
	\node[proprietaryb,right=of Protocols] (JSTP) {JSTP};
	\node[blueb,right=of JSTP] (HTTP) {HTTP};
	\node[blueb,right=of HTTP] (FileP) {FTP, SMB};
	\node[blueb,right=of FileP] (SQLP) {SQL queries};

	\node[layerb,below=of Protocols] (Servers) {\textbf{Servers}};
	\node[proprietaryb,right=of Servers] (DataS) {Data RPC};
	\node[blueb,right=of DataS] (WebS) {Static web};
	\node[blueb,right=of WebS] (FileS) {File servers};
	\node[blueb,right=of FileS] (SQLS) {PostgreSQL};

	\node[layerb,below=of Servers] (Data) {\textbf{Data Store}};
	\node[blueb,right=of Data] (ROOT) {ROOT};
	\node[blueb,right=of ROOT,text width=5cm+10pt] (MF) {Multi-frame \& single-frame};
	\node[proprietaryb,right=of MF] (SQLD) {Index DB};

	\node[blueb,below=2.4cm of HTTP,text width=13cm+26pt] (FileSystem) {UNIX-like file system (possibly EOS)};

	\begin{pgfonlayer}{background}
	\draw[blueb,draw=black] 
	  ([xshift=-8pt,yshift=8pt]current bounding box.north west) rectangle 
	  ([xshift=8pt,yshift=-8pt]current bounding box.south east);
	\end{pgfonlayer}
	\end{tikzpicture}

\caption[Multi-layered system.]{A multi-layered system. Proprietary components are emphasized by gray color.}
\label{fig:multilayered-diagram}
\end{center}
\end{figure}

This may be illustrated on a practical application. Users who want a quick peek at the detector operation without any effort might decide to use the visualization UI in their web browser. The website is quite easy to use, does not require any particular skills to operate, and is capable of displaying frames captured by the detectors as well as overview of their operation. In contrast, users who want to retrieve data for experimentation or statistical aggregation might utilize SQL or JSTP as these two protocols are not designed to interact with humans, but with other applications, most notably usable in scripts designed for custom data processing. Lastly, users in need of information, which is not displayed by the visualization UI nor transmitted by any of the mentioned protocols, can connect to the database storage facility remotely and directly download data files by means of some of the supported network transfer protocols. This concept is illustrated in Figure \ref{fig:multilayered-diagram}.

% CITACE: konkurenční projekty
JSTP is built with extensibility in mind. With multiple concurrent projects such as MoEDAL-TPX\footnote{Similarly to ATLAS-TPX, MoEDAL-TPX is a network of Timepix devices installed within the MoEDAL experiment at CERN.}, SATRAM\footnote{SATRAM is a technology demonstration device carrying Timepix position-sensitive semiconductor pixel detector on board ESA’s Proba V satellite. \url{http://satram.utef.cvut.cz/}} and RISESat\footnote{RISESat is a microsatellite mission carrying several scientific instruments including a Timepix detector.}, it is likely that JSTP will be used for compatibility reasons in other applications as well. It should therefore allow for limited variability, gracefully handling minor alterations in transmitted data structures.

\subsection{Requirements}
This section lists all formal requirements on JSTP. The most basic requirement is that the protocol allows to retrieve frames captured by the ATLAS-TPX network by their start time and device of origin. This might remind observant readers of a similar requirement stated in the database definition (see section \ref{db:definition}), as it is the most likely user request. However unlike the database, JSTP must be able to transmit only those frames, which satisfy the user predicate, effectively reducing information overhead in transmitted messages to zero.

In the first version, JSTP is required only to transmit results of cluster analysis, leaving door open for pixel matrix transmissions in the future. This indirectly implies that every message transmitted through JSTP containing a captured frame consists of two parts: a header (containing detector configuration, position, orientation, etc.) and a body (containing a list of clusters, or possibly a pixel matrix).

To efficiently reference detectors in the ATLAS-TPX network, it is required that JSTP provides an exhaustive list of network elements along with information about their availability in the system. This might seem redundant at first, but consider that JSTP needs handle situations when detectors malfunction, are replaced, or new detectors are installed. Such events might not be that uncommon, especially given the experimental nature of the project.

Lastly, in order to aid with navigation in large amounts of detector footage, JSTP has to offer a mechanism to generate statistics over larger periods of time. This information will help users find events of interest in overwhelming quantities of white noise, resembling the proverbial \textit{needle in a haystack}.

Apart from various file management network protocols listed earlier, there are no data manipulation requirements on JSTP, implying that the protocol cannot be used for other than read-only access to detector footage.

\section{Underlying Standards}
JSTP is a web protocol and as such, it utilizes HTTP as its underlying standard, serving to abstract physical data transmission and compression. By this declaration, it is implied that JSTP is a request-response communication protocol between two types of agents: \textit{a server} and \textit{a client}.

In its architecture, JSTP consists of two parts: a web service providing API for remote procedure calls (RPC) and a data format built atop of it to facilitate such calls. Since JSTP does not include any universal service description mechanism such as WSDL or WADL, all clients need to know its capabilities and calling conventions prior to initiating communication with the server. For data serialization, JSTP utilizes JavaScript Object Notation (JSON) (hence its name). This format has been selected for various reasons. It is simple to parse, offers an extensible tree structure and is very common among web services of this kind, as it is directly supported by the JavaScript client-side runtime used in the web visualization UI. Apart from JSON, JSTP does not offer nor accept communication in any other data formats.

One might ask whether JSTP web methods meet the standards of RESTful web services. While it is true that the protocol shows many traits often attributed to RESTful services (client-server model, stateless protocol, cacheability, layered system), it certainly does not satisfy all of them. For example, JSTP does not uniquely identify resources by their URI because it does not offer any of the common CRUD operations. Moreover, in referencing entities, JSTP uses arbitrary identifiers (recall members \texttt{fid}, \texttt{frid} and \texttt{sid} of entities defined in section \ref{db:definition}), which are not passed in the URI but through an array in the request body. Moreover, JSTP does not offer a uniform interface, capable of negotiating data format according to client limitations. Instead, it forces clients to communicate strictly in JSON, adhering to its own arbitrary data structures and calling conventions.

\todo % revisions finished to this point

\section{Web Methods}
\label{jstp:web-methods}
The main component of JSTP is a web service, which can be described as a set of proprietary web methods. For the purpose of simplicity, in this section we provide only a semantical description of each method. Readers interested in full technical documentation of the methods are referred to Appendix \ref{apx:jstp-doc}.

\subsection{Detector List}
The first method is dedicated to providing an updated list of operational detectors in the ATLAS-TPX network.

As we mentioned earlier, we need to be ready for situations when the physical structure of the network changes due to malfunctions or upgrades. For these reasons, any client intending to retrieve frames from a specific detector must first consult the list provided by this method to verify, whether the device is still connected and operational. In addition, other clients unaware of the network's architecture may use this method to obtain an exhaustive listing of all currently available data sources.

Execution of this method requires no parameters. The server responds by transmitting a list of devices, from which data can be retrieved at the time of request. For detailed documentation of this method including examples of requests and responses, see section \ref{apx:jstp-sensors} of the Appendix.

\subsection{Overview of Acquisition}
To satisfy demands on navigation in voluminous amounts of data, we dedicate the second web method to providing an overview on detector acquisition. This is achieved by uniformly dividing a specific time period into finitely many time intervals, in which all relevant frames are gathered with respect to their start time (acquisition time is not considered). In every interval, frames are subsequently processed to produce aggregate statistics, which might indicate time points, where frames of interest are located. This approach is in its essence very similar to the binning procedure used when constructing histograms.

Clients calling this method are required to transmit five parameters in their request:

\begin{description}
	\item[Detector Predicate]
	A group of detector identifiers, restricting all processed frames by their device of origin.

	\item[Start Time, End Time]
	These parameters define the time period, in which we generate statistics. Obviously, the first parameter must be an earlier point of time than the latter.

	\item[Group Period]
	The duration of every interval in the partitioning of the time period. Should an imperfect partitioning occur, the number of intervals is always rounded up to the nearest integer, possibly exceeding the specified end time.

	Longer durations obviously result in a lower number of intervals, and in turn a lower number of returned data points. Shorter durations yield more data points, but may result in lengthy processing at server-side. For stability reasons, the server therefore requires that the duration of the group period results in at least 1 and at most 1024 intervals.

	\item[Normalized Mode]
	An option to compensate possible data distortions caused by variations in frame acquisition times. This setting is irrelevant in configurations, where users can be certain such variations do not occur.
\end{description}

If the server finds request parameters to be valid and succeeds in generating requested statistics, it responds by transmitting a list of data points, corresponding with intervals of the partitioning of the specified time period. Every data point includes three values:

\begin{description}
	\item[Cluster Counts]
	Sums of cluster counts from every frame in the interval, summed separately per every of the six cluster types (for type definitions, see section \ref{db:shape-classification}).

	\item[Frame Occupancy]
	Total number of non-zero pixels in all frames in the interval, indicating their levels of saturation.

	\item[Number of Frames]
	The count of frames aggregated in the interval.
\end{description}

For detailed documentation of this method including examples of requests and responses, see section \ref{apx:jstp-timeline} of the Appendix.

\subsection{Frame Search}
The third method serves to retrieve frames captured at any given point in time by a detector (or a group of detectors). As the method's name might suggest, time need not be exact, resulting in a search for the nearest frame operating on the scope of the index database. There are several search modes available, each offering a different strategy to find \textit{the master frame}. Once such frame is identified, its start time is then used to locate other frames from the remaining detectors, yielding at most one frame per every detector. In the first version of JSTP, we support two search modes:

\begin{description}
	\item[Sequential Forward Mode]
	The master frame is the frame with the start time nearest to, but greater or equal than the time parameter of the search.

	\item[Sequential Backward Mode]
	The master frame is the frame with the start time nearest to, but lower or equal than the time parameter of the search.

	%\item[Sequential Omnidirectional Mode]
	%\item[Exact Match Mode]
\end{description}

Let us demonstrate operation of these modes on a real world example. Suppose that we are interested in frames captured by two devices. Detector 1 captures frames every 0.25 seconds with acquisition time of 0.05 seconds, whereas detector 2 captures frames every 0.33 seconds with acquisition time of 0.27 seconds. If we set the search time to 0.4 seconds and search in the forward mode, the third frame captured by detector 1 will be designated as the master frame. Since the start time of this frame is 0.5 seconds, the second chosen frame will be the second frame captured by detector 2 as its start time is 0.33 seconds and its end time is 0.6 seconds. This scenario is depicted in Figure \ref{fig:frame-search-forward}. If we to use the backward mode instead, the second frame captured by detector 2 will be designated as the master frame. Since its start time is 0.33 seconds and there is a gap in detector 1 footage between 0.3 seconds (end time of the second frame) and 0.5 seconds (start time of the third frame), the algorithm will return no frame for the other detector. This is illustrated in Figure \ref{fig:frame-search-backward}.

% TODO: doplnit dva obrázky

\begin{figure}[t]
\begin{center}
	\begin{subfigure}[b]{0.4\textwidth}
	\Large
	\begin{tikztimingtable}
		\textnormal{D1}   & zz D{1}zzzz D{2}zzzz D{3}zzzz ;[fill=yellow!50]D{4};[fill=none] zzzz D{}         \\
		\textnormal{D2}   & zz 5D{1}z ;[fill=gray!30]5D{2};[fill=none]z 2D{}  \\
		\textnormal{D3}   & zz 2D{1}z   2D{2}z   2D{3}z   ;[fill=gray!30]2D{4};[fill=none] z    2D{5}z 0.5D{}   \\
		\extracode
	\begin{pgfonlayer}{background}
	\vertlines[help  lines]{1,9,10,13}
	\end{pgfonlayer}
	\end{tikztimingtable}
	\caption{Forward search.}
	\label{fig:frame-search-forward}
	\end{subfigure}
	~ %spacing
	\begin{subfigure}[b]{0.4\textwidth}\Large
	\begin{tikztimingtable}
		\textnormal{D1}   & zz D{1}zzzz D{2}zzzz D{3}zzzz D{4}zzzz D{}         \\
		\textnormal{D2}   & zz 5D{1}z ;[fill=gray!30]5D{2};[fill=none]z 2D{}  \\
		\textnormal{D3}   & zz 2D{1}z   2D{2}z   2D{3}z   ;[fill=yellow!50]2D{4};[fill=none] z    2D{5}z 0.5D{}   \\
		\extracode
	\begin{pgfonlayer}{background}
	\vertlines[help  lines]{1,8.5,9,13}
	\end{pgfonlayer}
	\end{tikztimingtable}
	\caption{Backward search.}
	\label{fig:frame-search-backward}
	\end{subfigure}

\caption{Time diagram of frame search illustrating behavioral differences between search modes. Individual blocks correspond with periods of detector acquisition. Emphasized blocks are returned as the search result (yellow marks the master frame).}
\label{fig:frame-search}
\end{center}
\end{figure}

To summarize, clients calling this method are required to specify four parameters:
\begin{description}
	\item[Time of Search]
	The point in time used as a starting point of the search.

	\item[Detector Predicate]
	A group of detector identifiers, restricting retrieved frames by their device of origin.

	\item[Search Mode]
	A strategy to select the master frame based on the time of search and available detector footage.

	\item[Integral Frames]
	Number of consecutive frames to be integrated for every device.
\end{description}

If the server finds request parameters to be valid and succeeds in locating at least one frame, it responds by transmitting the start time of the master frame, followed by headers and bodies of all found frames, corresponding with the order of identifiers in the detector predicate of the request. Frame bodies are transmitted in the form of cluster lists (for properties of clusters, see section \ref{db:cluster-properties}). Detailed documentation of this method, including examples of requests and responses, is available in section \ref{apx:jstp-frame} of the Appendix.

\section{Miscellaneous}
JSTP has been originally designed to serve solely as a data transmission component of the visualization UI. Over time, it has however grown to be a more complex protocol, with applications in other projects than ATLAS-TPX and outside the conventional task of data visualization. It is the intention of author to continue development of this protocol with further releases in the future, eventually decoupling it from the Timepix chip and abstracting it to the point where it could be utilized in combinations with different hardware.

Since the amount of data in our database is expected to become rather overwhelming, the protocol itself is structured and meant to be used in a top-down model (see Figure \ref{fig:jstp-uml}), allowing clients to gradually refine parameters of their requests and locate the information they seek, while avoiding transmission of data in overly granular bulks. In other cases, the protocol minimizes information overhead by requiring strong usage of predicates operating on the index database.

Note that in the protocol definition, we do not specify whether the results of individual web method calls are cacheable by clients. This is due to the diversified nature of its applications. Since HTTP already contains its own caching logic\footnote{Caching in HTTP is controlled by values of headers provided in every response message. Relevant header names are: \texttt{Cache-Control}, \texttt{Expires} and \texttt{Pragma}.}, we encourage all clients to comply with strategies described in \cite{HTTP1999}, section 13, as JSTP servers are permitted to use this mechanism to emply different caching policies for individual response messages. Analogous declaration is used for data compression (for HTTP specification, see section 3.5 of \cite{HTTP1999}).

\begin{figure}[t]
\begin{center}
	\begin{sequencediagram}
		\newthread{c}{:JstpClient}
		\newinst[2]{s}{:JstpServer}
		\newinst[1]{idb}{:IndexDatabase}
		\newinst{fdb}{:FileDatabase}

		\begin{call}{c}{detectorList()}{s}{device list}
			\begin{call}{s}{selectSensors()}{idb}{device list}
			\end{call}
		\end{call}
		
		\begin{sdblock}{Until significant data is found}{}
			\begin{call}{c}{acqOverview()}{s}{statistics}
				\begin{call}{s}{selectFiles()}{idb}{affected files}
				\end{call}
				\begin{call}{s}{selectFrames()}{idb}{statistics}
					\begin{callself}{idb}{\small aggregate()}{}
					\end{callself}
				\end{call}
			\end{call}
		\end{sdblock}
		
		\begin{call}{c}{frameSearch()}{s}{found frames}
			\begin{call}{s}{selectFrames()}{idb}{master frame}
			\end{call}
			\begin{sdblock}{For every device}{}
				\begin{call}{s}{selectFrames()}{idb}{entry indices}
				\end{call}
				\begin{call}{s}{readFile()}{fdb}{frame contents}
				\end{call}
			\end{sdblock}
		\end{call}
	\end{sequencediagram}

\caption{UML diagram depicting expected interactions between JSTP client and server, hinting levels of processing complexity at server-side.}
\label{fig:jstp-uml}
\end{center}
\end{figure}









